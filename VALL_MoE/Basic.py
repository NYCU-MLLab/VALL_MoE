from utils.generation import SAMPLE_RATE, generate_audio, preload_models
from scipy.io.wavfile import write as write_wav
from IPython.display import Audio
from utils.prompt_making import make_prompt
import torch


#make_prompt(name="nycuka2", audio_prompt_path="prompts/nycuka2.wav")

# def get_model_file_size(path):
#     model_state = torch.load(path, map_location='cpu' ,weights_only=False)

#     if 'model' in model_state:
#         model_state = model_state['model']  # icefall æ ¼å¼é€šå¸¸æ˜¯é€™æ¨£

#     total_params = sum(p.numel() for p in model_state.values())
#     total_bytes = sum(p.numel() * p.element_size() for p in model_state.values())
#     print(f"ğŸ”¢ Total parameters: {total_params:,}")
#     print(f"ğŸ“¦ Total size: {total_bytes / (1024 ** 2):.2f} MB")

# # ç¯„ä¾‹
# get_model_file_size("/home/VALL-E-X-Trainer-by-CustomData/exp/valle/best-train-loss.pt")

## EN prompt:en2zh_tts_4

# zh_prompt =  """
# è±†è…ç‚ºä»€éº¼èƒ½æ‰“å‚·äºº
# """

# text_prompt = """
#     [ZH]é€™å€‹[ZH] 
#     [EN]restaurant[EN] 
#     [ZH]å¾ˆæœ‰å[ZH]
#     [ZH]å¾ˆå¤šäººéƒ½ä¾†åƒ[ZH]
#     """

###############################################


#######################################################
# #china
# preload_models("/home/VALL-E-X-Trainer-by-CustomData/exp/valle/epoch-500000.pt")

# # generate audio from text

# audio_array = generate_audio(text_prompt,prompt="zh2en_tts_2",language="mix")

# # save audio to disk
# write_wav("vallex_premix.wav", SAMPLE_RATE, audio_array)

# # play text in notebook|
# Audio(audio_array, rate=SAMPLE_RATE)

#######################################################################################



mix_prompt = """
    [ZH]é€™å€‹[ZH]
    [EN]language model[EN]
    [ZH]å¾ˆå¥½ç”¨åŠŸèƒ½å¾ˆå¤š[ZH]
    """

one_prompt =  """   
He honours whatever he recognizes in himself, such morality equals self glorification.
"""

#######################################################################################
####withç”¨jsï¼Œfinetuneç”¨newtai 

# taiwan_validloss
preload_models("exp/valle/epoch-500150.pt")

# generate audio from text en2zh_tts_3

########################withç”¨jsï¼Œfinetuneç”¨newtai ###########################

###zh or en
audio_array = generate_audio(one_prompt,prompt="en2zh_tts_3")

##mix
#audio_array = generate_audio(mix_prompt,ËŠ="newtai",language="mix")



# save audio to disk
write_wav("MoEnycuka.wav", SAMPLE_RATE,audio_array)

# play text in notebook
Audio(audio_array, rate=SAMPLE_RATE)

##############################################################################################################



#######################################################################################
# # Taiwan_ephco
# preload_models("/home/VALL-E-X-Trainer-by-CustomData/exp/valle/epoch-500275.pt")

# # generate audio from text



# audio_array = generate_audio(text_prompt,prompt="zh2en_tts_2",language="mix")

# # save audio to disk
# write_wav("vallex_tai_epoch_mix.wav", SAMPLE_RATE, audio_array)

# # play text in notebook
# Audio(audio_array, rate=SAMPLE_RATE)

##############################################################################################################




# import h5py
# import os
# import numpy as np




# import soundfile as sf

# h5_path = "/home/VALL-E-X-Trainer-by-CustomData/taiwna_data/audio_sum.hdf5"
# ann_path = "/home/VALL-E-X-Trainer-by-CustomData/taiwna_data/audio_ann_sum.txt"
# audio_folder = "/home/VALL-E-X-Trainer-by-CustomData/taiwna_data/"  # ä½ çš„éŸ³æª”è³‡æ–™å¤¾

# # è®€å–æ¨™è¨»ä¸­çš„éŸ³è¨Šæ™‚é•·
# ann_durations = {}
# with open(ann_path, "r", encoding="utf-8") as f:
#     for line in f:
#         parts = line.strip().split("|")
#         ann_durations[parts[0]] = float(parts[1])

# # æª¢æŸ¥ HDF5 å…§çš„éŸ³è¨Šé•·åº¦
# with h5py.File(h5_path, "r") as f:
#     for key in f.keys():
#         try:
#             # è§£æ uttX_Y â†’ uttX è³‡æ–™å¤¾ & Y æª”å
#             utt_folder, file_id = key.split("_")  # e.g., utt1_2 â†’ utt1, 2
#             audio_path = os.path.join(audio_folder, utt_folder, file_id + ".wav")
            
#             if os.path.exists(audio_path):
#                 # è®€å–åŸå§‹éŸ³æª”
#                 audio, sr = sf.read(audio_path)
#                 duration = len(audio) / sr

#                 # æ¯”å°æ¨™è¨»æ™‚é•·
#                 if abs(duration - ann_durations[key]) > 0.2:  # å®¹è¨± 0.2 ç§’èª¤å·®
#                     print(f"âš ï¸ {key} æ™‚é•·ä¸åŒ¹é…: æ¨™è¨» {ann_durations[key]}sï¼Œå¯¦éš› {duration}s")
#                 else:
#                     print(f"âœ… {key} æ™‚é•·åŒ¹é…")
#             else:
#                 print(f"âŒ æ‰¾ä¸åˆ°å°æ‡‰éŸ³æª”: {audio_path}")

#         except Exception as e:
#             print(f"âŒ {key} ç™¼ç”ŸéŒ¯èª¤: {e}")